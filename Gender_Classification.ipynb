{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12c4dc6",
   "metadata": {},
   "source": [
    "#### üì¶ Importing Required Libraries\n",
    "We import PyTorch, TorchVision, scikit-learn, and other utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037030e2-25dc-4f92-9594-32fcac258fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae40d8b",
   "metadata": {},
   "source": [
    "#### üîß Setting Device and Random Seed\n",
    "This ensures reproducibility and leverages GPU acceleration if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6cc07ef-f802-428d-9f8a-9271c3ac1ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b4fe6adc10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf5a713-5a25-4db3-b39b-b62294099bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b89a5c",
   "metadata": {},
   "source": [
    "#### üîÑ Data Preprocessing & Augmentation\n",
    "We define transformations for both training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c916c5-4505-4364-8b47-e79373904dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32033e",
   "metadata": {},
   "source": [
    "#### üìÇ Loading Dataset\n",
    "Dataset is structured with `train/` and `val/` directories, each containing `male/` and `female/` subfolders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7135feee-860b-4710-b134-3355c21ec0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = 'Task_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e5adbf-3178-4d82-910a-b5133b29cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 1926, 'val': 422}\n"
     ]
    }
   ],
   "source": [
    "# Datasets and loaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(f\"Dataset sizes: {dataset_sizes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a69dc",
   "metadata": {},
   "source": [
    "#### üß† Model Architecture: Custom ResNet50\n",
    "We use a pre-trained ResNet50, freeze 1st layer, and add a custom classifier head for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a0371a-67a1-4ce1-9884-839f4ffb8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ResNet50 model\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Unfreeze layer2 and layer3 and layer4\n",
    "        for name, param in base_model.named_parameters():\n",
    "            if 'layer2' in name or 'layer3' in name or 'layer4' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)  # binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2bf1f8-fcf8-4ab0-9c04-7d0018576488",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = CustomResNet50().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9cfde",
   "metadata": {},
   "source": [
    "#### ‚öôÔ∏è Define Loss Function, Optimizer, and Scheduler\n",
    "We use CrossEntropy with label smoothing and apply weight decay regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d80cd9-832a-49e9-8e36-34165141cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet50.parameters()), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cd18a",
   "metadata": {},
   "source": [
    "#### üèãÔ∏è‚Äç‚ôÇÔ∏è Model Training Loop\n",
    "Training and validation loops are implemented with metrics logged for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0b5bfa-476a-410b-8ca6-5b5a0a62b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(resnet50.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc74cdc-74f1-4a2f-a8d6-a73662cd92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list, val_acc_list = [], []\n",
    "train_loss_list, val_loss_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c2a991-7f35-43ef-8197-74c80b39471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "--------------------\n",
      "train Loss: 0.3954 Acc: 0.8738\n",
      "val Loss: 0.3581 Acc: 0.8981\n",
      "\n",
      "Epoch 2/30\n",
      "--------------------\n",
      "train Loss: 0.3436 Acc: 0.9133\n",
      "val Loss: 0.3003 Acc: 0.9455\n",
      "\n",
      "Epoch 3/30\n",
      "--------------------\n",
      "train Loss: 0.3203 Acc: 0.9315\n",
      "val Loss: 0.3217 Acc: 0.9313\n",
      "\n",
      "Epoch 4/30\n",
      "--------------------\n",
      "train Loss: 0.3177 Acc: 0.9367\n",
      "val Loss: 0.3262 Acc: 0.9360\n",
      "\n",
      "Epoch 5/30\n",
      "--------------------\n",
      "train Loss: 0.3089 Acc: 0.9330\n",
      "val Loss: 0.3100 Acc: 0.9408\n",
      "\n",
      "Epoch 6/30\n",
      "--------------------\n",
      "train Loss: 0.3005 Acc: 0.9460\n",
      "val Loss: 0.3400 Acc: 0.9194\n",
      "\n",
      "Epoch 7/30\n",
      "--------------------\n",
      "train Loss: 0.2979 Acc: 0.9408\n",
      "val Loss: 0.3582 Acc: 0.8981\n",
      "\n",
      "Epoch 8/30\n",
      "--------------------\n",
      "train Loss: 0.2875 Acc: 0.9470\n",
      "val Loss: 0.3917 Acc: 0.9028\n",
      "\n",
      "Epoch 9/30\n",
      "--------------------\n",
      "train Loss: 0.2899 Acc: 0.9470\n",
      "val Loss: 0.3320 Acc: 0.9313\n",
      "\n",
      "Epoch 10/30\n",
      "--------------------\n",
      "train Loss: 0.2923 Acc: 0.9491\n",
      "val Loss: 0.3345 Acc: 0.9194\n",
      "\n",
      "Epoch 11/30\n",
      "--------------------\n",
      "train Loss: 0.2772 Acc: 0.9559\n",
      "val Loss: 0.3340 Acc: 0.9265\n",
      "\n",
      "Epoch 12/30\n",
      "--------------------\n",
      "train Loss: 0.2644 Acc: 0.9637\n",
      "val Loss: 0.3375 Acc: 0.9265\n",
      "\n",
      "Epoch 13/30\n",
      "--------------------\n",
      "train Loss: 0.2652 Acc: 0.9631\n",
      "val Loss: 0.3190 Acc: 0.9408\n",
      "\n",
      "Epoch 14/30\n",
      "--------------------\n",
      "train Loss: 0.2573 Acc: 0.9657\n",
      "val Loss: 0.3343 Acc: 0.9289\n",
      "\n",
      "Epoch 15/30\n",
      "--------------------\n",
      "train Loss: 0.2571 Acc: 0.9688\n",
      "val Loss: 0.3390 Acc: 0.9265\n",
      "\n",
      "Epoch 16/30\n",
      "--------------------\n",
      "train Loss: 0.2540 Acc: 0.9725\n",
      "val Loss: 0.3301 Acc: 0.9360\n",
      "\n",
      "Epoch 17/30\n",
      "--------------------\n",
      "train Loss: 0.2549 Acc: 0.9678\n",
      "val Loss: 0.3369 Acc: 0.9336\n",
      "\n",
      "Epoch 18/30\n",
      "--------------------\n",
      "train Loss: 0.2617 Acc: 0.9621\n",
      "val Loss: 0.3270 Acc: 0.9265\n",
      "\n",
      "Epoch 19/30\n",
      "--------------------\n",
      "train Loss: 0.2509 Acc: 0.9714\n",
      "val Loss: 0.3669 Acc: 0.9194\n",
      "\n",
      "Epoch 20/30\n",
      "--------------------\n",
      "train Loss: 0.2444 Acc: 0.9777\n",
      "val Loss: 0.3495 Acc: 0.9289\n",
      "\n",
      "Epoch 21/30\n",
      "--------------------\n",
      "train Loss: 0.2435 Acc: 0.9756\n",
      "val Loss: 0.3493 Acc: 0.9265\n",
      "\n",
      "Epoch 22/30\n",
      "--------------------\n",
      "train Loss: 0.2470 Acc: 0.9720\n",
      "val Loss: 0.3423 Acc: 0.9289\n",
      "\n",
      "Epoch 23/30\n",
      "--------------------\n",
      "train Loss: 0.2423 Acc: 0.9777\n",
      "val Loss: 0.3439 Acc: 0.9289\n",
      "\n",
      "Epoch 24/30\n",
      "--------------------\n",
      "train Loss: 0.2395 Acc: 0.9792\n",
      "val Loss: 0.3468 Acc: 0.9313\n",
      "\n",
      "Epoch 25/30\n",
      "--------------------\n",
      "train Loss: 0.2366 Acc: 0.9808\n",
      "val Loss: 0.3440 Acc: 0.9313\n",
      "\n",
      "Epoch 26/30\n",
      "--------------------\n",
      "train Loss: 0.2470 Acc: 0.9746\n",
      "val Loss: 0.3446 Acc: 0.9313\n",
      "\n",
      "Epoch 27/30\n",
      "--------------------\n",
      "train Loss: 0.2420 Acc: 0.9798\n",
      "val Loss: 0.3503 Acc: 0.9265\n",
      "\n",
      "Epoch 28/30\n",
      "--------------------\n",
      "train Loss: 0.2371 Acc: 0.9798\n",
      "val Loss: 0.3501 Acc: 0.9265\n",
      "\n",
      "Epoch 29/30\n",
      "--------------------\n",
      "train Loss: 0.2400 Acc: 0.9813\n",
      "val Loss: 0.3494 Acc: 0.9265\n",
      "\n",
      "Epoch 30/30\n",
      "--------------------\n",
      "train Loss: 0.2531 Acc: 0.9725\n",
      "val Loss: 0.3551 Acc: 0.9194\n",
      "\n",
      "Training complete. Best val Acc: 0.9455\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 20)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            resnet50.train()\n",
    "        else:\n",
    "            resnet50.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = resnet50(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_loss_list.append(epoch_loss)\n",
    "            train_acc_list.append(epoch_acc.item())\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            val_loss_list.append(epoch_loss)\n",
    "            val_acc_list.append(epoch_acc.item())\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(resnet50.state_dict())\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "print(f\"\\nTraining complete. Best val Acc: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d1b1d-a485-485d-a738-4eaae455013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.load_state_dict(best_model_wts)  # ‚úÖ Restore best weights\n",
    "torch.save(resnet50.state_dict(), 'Gender_Classification_model.pt')  # Save the  model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c682518",
   "metadata": {},
   "source": [
    "#### üìà Evaluation on Training and Validation Sets\n",
    "Metrics include Accuracy, Precision, Recall, and F1-Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce6f56-8922-45d8-bf4f-9c8aded80094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating best saved model on training and validation sets...\n",
      "\n",
      "üìä Evaluation on Training Set:\n",
      "  - Accuracy : 0.9346\n",
      "  - Precision: 0.9426\n",
      "  - Recall   : 0.9821\n",
      "  - F1-Score : 0.9620\n",
      "\n",
      "üìä Evaluation on Validation Set:\n",
      "  - Accuracy : 0.9455\n",
      "  - Precision: 0.9651\n",
      "  - Recall   : 0.9679\n",
      "  - F1-Score : 0.9665\n"
     ]
    }
   ],
   "source": [
    "# ===== Evaluate Best Saved Model on Validation and Training Sets =====\n",
    "print(\"\\nüîç Evaluating best saved model on training and validation sets...\")\n",
    "\n",
    "# Load the best model weights\n",
    "resnet50.load_state_dict(torch.load('Gender_Classification_model.pt'))\n",
    "resnet50.eval()\n",
    "\n",
    "def evaluate_model(dataloader, dataset_name=\"Dataset\"):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = resnet50(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\nüìä Evaluation on {dataset_name}:\")\n",
    "    print(f\"  - Accuracy : {acc:.4f}\")\n",
    "    print(f\"  - Precision: {prec:.4f}\")\n",
    "    print(f\"  - Recall   : {rec:.4f}\")\n",
    "    print(f\"  - F1-Score : {f1:.4f}\")\n",
    "\n",
    "# Evaluate on training set\n",
    "evaluate_model(dataloaders['train'], dataset_name=\"Training Set\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluate_model(dataloaders['val'], dataset_name=\"Validation Set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31621451",
   "metadata": {},
   "source": [
    "#### üß™ Test Script (test_Gender_Classification_model.py)\n",
    "This standalone script accepts test data directory and model path and prints evaluation metrics. It uses the same model architecture and transforms as in training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944c235e-4deb-4279-8cdd-630e5bc200b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_Gender_Classification_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_Gender_Classification_model.py\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        for name, param in base_model.named_parameters():\n",
    "            if 'layer2' in name or 'layer3' in name or 'layer4' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"üìä Evaluation Metrics on Test Set:\")\n",
    "    print(f\"  - Accuracy : {acc:.4f}\")\n",
    "    print(f\"  - Precision: {prec:.4f}\")\n",
    "    print(f\"  - Recall   : {rec:.4f}\")\n",
    "    print(f\"  - F1-Score : {f1:.4f}\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, required=True, help='Path to test data directory')\n",
    "    parser.add_argument('--weights', type=str, default='Gender_Classification_model.pt', help='Path to saved model weights')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(args.data_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = CustomResNet50().to(device)\n",
    "    model.load_state_dict(torch.load(args.weights, map_location=device))\n",
    "\n",
    "    evaluate(model, test_loader, device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ad21b-6ad1-47f0-8272-3776b11d0715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
